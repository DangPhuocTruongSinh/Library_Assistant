from typing import List, Optional
from pathlib import Path
from pydantic import BaseModel, Field

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

from database.connection import pdf_reader_llm
from core.pdf_reader_toolbox.reference_search import ReferenceRetrievalSystem
from core.ingestion.docling_loader import PDFIngestionPipeline

from log.logger_config import setup_logging
logger = setup_logging(__name__)


# --- Data Models for Structured Output ---
class Answer(BaseModel):
    answer: str = Field(description="The answer to the user's question based on the provided context.")

class QueryAnalysis(BaseModel):
    """Ph√¢n t√≠ch √Ω ƒë·ªãnh ng∆∞·ªùi d√πng ƒë·ªÉ ch·ªçn chi·∫øn l∆∞·ª£c t√¨m ki·∫øm."""
    intent: str = Field(description="√ù ƒë·ªãnh: 'summary' (t√≥m t·∫Øt/t·ªïng quan/ti√™u ƒë·ªÅ/t√™n file), 'section' (t√¨m m·ª•c c·ª• th·ªÉ), ho·∫∑c 'general' (h·ªèi ƒë√°p th√¥ng th∆∞·ªùng)")
    target_heading: Optional[str] = Field(description="T√™n ƒë·ªÅ m·ª•c ti·ªÅm nƒÉng c·∫ßn t√¨m (n·∫øu intent l√† 'section')")
    refined_query: str = Field(description="C√¢u truy v·∫•n ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ƒë·ªÉ t√¨m ki·∫øm vector")


# --- Retriever Instance ---
retriever = ReferenceRetrievalSystem(collection_name="PDF_Reader")


# --- Load System Prompt ---
def _load_prompt() -> str:
    """Load system prompt from file."""
    prompt_path = Path(__file__).parent.parent / "prompts" / "book_reader_prompt.md"
    if prompt_path.exists():
        with open(prompt_path, "r", encoding="utf-8") as f:
            return f.read()
    return ""


class PDFReaderAgent:
    """
    Agent for reading and answering questions about PDFs using Structured RAG.
    """
    
    def __init__(self):
        self.llm = pdf_reader_llm
        self.system_prompt = _load_prompt()
        
        self.structured_llm = self.llm.with_structured_output(Answer)
        
        # PLANNER: Analyzes query intent to choose search strategy
        self.planner = self.llm.with_structured_output(QueryAnalysis)
        
        # Setup Prompt Template
        self.prompt = PromptTemplate(
            template="""
{system_prompt}

## Context Information:
{context}

## Conversation History:
{chat_history}

## User Question:
{question}

## Instructions:
1. Answer the question based ONLY on the provided context.
2. If the context does not contain the answer, say "I cannot find the information in the document."
3. DO NOT use any [ref_x] markers or source references in your answer.
4. Answer in a natural, helpful way.
5. You MUST return a valid JSON object matching the requested schema.
""",
            input_variables=["system_prompt", "context", "chat_history", "question"]
        )
        
        logger.info("‚úÖ PDFReaderAgent (Structured Output Mode) initialized.")
    
    def ask(self, question: str, chat_history: list = None) -> dict:
        """
        Ask a question about the PDF.
        
        Returns:
            dict: {
                "answer": str
            }
        """
        try:
            logger.info(f"‚ùì PDF Chat Question: {question}")

            # --- STEP 1: QUERY ANALYSIS ---
            # ƒê·ªÉ Agent t·ª± hi·ªÉu √Ω ƒë·ªãnh thay v√¨ d√πng hardcode keywords
            analysis = self.planner.invoke(f"""
            Ph√¢n t√≠ch c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ƒë·ªÉ x√°c ƒë·ªãnh chi·∫øn l∆∞·ª£c t√¨m ki·∫øm RAG t·ªëi ∆∞u.
            - 'summary': C√°c c√¢u h·ªèi chung v·ªÅ t√†i li·ªáu (n·ªôi dung ch√≠nh, t√≥m t·∫Øt, ti√™u ƒë·ªÅ, t√°c gi·∫£, √Ω nghƒ©a, b√†i h·ªçc, ch·ªß ƒë·ªÅ).
            - 'section': C√°c c√¢u h·ªèi v·ªÅ m·ªôt ph·∫ßn c·ª• th·ªÉ (v√≠ d·ª•: Methodology, Conclusion, K·∫øt qu·∫£, Ki·∫øn tr√∫c).
            - 'general': C√°c c√¢u h·ªèi c·ª• th·ªÉ v·ªÅ s·ª± ki·ªán/th√¥ng tin b√™n trong.
            
            C√¢u h·ªèi: {question}
            """)
            
            logger.info(f"üß† Intent: {analysis.intent} | Target: {analysis.target_heading} | Query: {analysis.refined_query}")

            docs = []
            
            # --- STEP 2: EXECUTE SEARCH STRATEGY ---
            
            # Lu√¥n b·∫Øt ƒë·∫ßu b·∫±ng Semantic Search c∆° b·∫£n (Top 5 trang)
            base_docs = retriever.search(analysis.refined_query, top_k=5, expand_same_page=True)
            docs.extend(base_docs)
            
            # Chi·∫øn l∆∞·ª£c b·ªï sung d·ª±a tr√™n intent
            if analysis.intent == "summary":
                logger.info("üîç Strategy: SUMMARY. Fetching Page 1, Last Page and Headings...")
                # L·∫•y trang 1 v√† trang cu·ªëi l√†m context t·ªïng quan
                max_p = retriever.get_max_page()
                target_pages = [1]
                if max_p > 1:
                    target_pages.append(max_p)
                
                docs.extend(retriever.get_intro_chunks(pages=target_pages))
                # T√¨m th√™m c√°c heading quan tr·ªçng
                docs.extend(retriever.search(analysis.refined_query, top_k=3, filter={"type": "heading"}))

            elif analysis.intent == "section":
                target = analysis.target_heading or analysis.refined_query
                logger.info(f"üîç Strategy: SECTION. Finding heading: '{target}'")
                
                heading_candidates = retriever.search(target, top_k=1, filter={"type": "heading"})
                if heading_candidates:
                    best_heading = heading_candidates[0]
                    heading_text = best_heading.page_content
                    logger.info(f"    Found heading: '{heading_text}'. Fetching related content...")
                    
                    section_content = retriever.fetch_by_metadata({"parent_heading": heading_text}, limit=30)
                    docs.append(best_heading)
                    docs.extend(section_content)
            
            # --- STEP 3: DEDUPLICATE CONTEXT ---
            unique_docs = []
            seen_contents = set()
            for d in docs:
                if d.page_content not in seen_contents:
                    unique_docs.append(d)
                    seen_contents.add(d.page_content)
            
            docs = unique_docs
            logger.info(f"üìÑ Final Context Size: {len(docs)} unique chunks.")
            
            if not docs:
                logger.warning("‚ö†Ô∏è No documents found for the query.")
                return {
                    "answer": "Ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c m·ªü ho·∫∑c kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan."
                }
            
            # 2. Format Context
            context_parts = []
            doc_map = {} # Map ref_id to document object
            
            for i, doc in enumerate(docs):
                ref_id = f"ref_{i+1}"
                doc_map[ref_id] = doc
                
                # Extract metadata
                meta = doc.metadata
                page = meta.get("page", "N/A")
                source = meta.get("filename", "Unknown PDF")
                heading = meta.get("parent_heading", "")
                content_type = meta.get("type", "")
                content = doc.page_content
                
                # Construct context block with available metadata
                context_block = f"--- DOCUMENT CHUNK {ref_id} ---\n"
                context_block += f"Source: {source}\n"
                context_block += f"Page: {page}\n"
                if heading:
                    context_block += f"Section: {heading}\n"
                if content_type:
                    context_block += f"Type: {content_type}\n"
                context_block += f"Content:\n{content}\n"
                
                context_parts.append(context_block)
            
            context_str = "\n\n".join(context_parts)
            
            # 3. Generate Answer
            if chat_history is None:
                chat_history = []
            
            history_str = "\n".join([f"{role}: {content}" for role, content in chat_history])
            
            _input = self.prompt.format_prompt(
                system_prompt=self.system_prompt,
                context=context_str,
                chat_history=history_str,
                question=question
            )
            
            parsed_result = self.structured_llm.invoke(_input.to_string())
            
            answer_text = parsed_result.answer

            logger.info(f"ü§ñ AI Answer: {answer_text[:200]}...") # Log first 200 chars

            return {
                "answer": answer_text
            }

        except Exception as e:
            logger.error(f"‚ùå Error in PDFReaderAgent.ask: {e}")
            return {
                "answer": f"ƒê√£ x·∫£y ra l·ªói: {str(e)}"
            }

    
    def load_pdf(self, pdf_path: str) -> bool:
        """Load and index a new PDF file."""
        try:
            # 1. Clear old data
            retriever.clear_collection()
            
            # 2. Parse PDF
            loader = PDFIngestionPipeline()
            docs = loader.process_pdf(pdf_path)
            
            # 3. Index into Chroma
            retriever.index_documents(docs)
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error loading PDF: {e}")
            return False
    
    def get_stats(self) -> dict:
        """Get stats about the current PDF."""
        return retriever.get_stats()


# --- Factory function ---
def get_pdf_reader_agent() -> PDFReaderAgent:
    """Return PDFReaderAgent instance."""
    return PDFReaderAgent()


# # --- Test ---
# if __name__ == "__main__":
#     agent = PDFReaderAgent()
    
#     # Test load PDF (optional, comment out if already loaded)
#     # pdf_path = "/home/sinhdang/Documents/Program/Chatbot_ThuVien/2501.17887v1.pdf"
#     # agent.load_pdf(pdf_path)
    
#     print("="*50)
#     print("üß™ Test Structured RAG with History:")
#     print("="*50)
    
#     chat_history = []
    
#     questions = [
#         "Docling l√† g√¨?",
#         "N√≥ c√≥ h·ªó tr·ª£ OCR kh√¥ng?",
#     ]
    
#     for q in questions:
#         print(f"\n‚ùì {q}")
#         result = agent.ask(q, chat_history=chat_history)
#         print(f"üí¨ Answer: {result['answer']}")
            
#         # Update history
#         chat_history.append(("human", q))
#         chat_history.append(("ai", result['answer']))
